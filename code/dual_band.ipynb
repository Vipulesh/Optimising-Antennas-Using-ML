{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>S12</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-42.088073</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.009</td>\n",
       "      <td>-42.496948</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.018</td>\n",
       "      <td>-42.873036</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.027</td>\n",
       "      <td>-43.132955</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.036</td>\n",
       "      <td>-43.179753</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Frequency        S12  el1   h1  l1  m2  px  py\n",
       "0      1.000 -42.088073    6  0.8   6   2  30  30\n",
       "1      1.009 -42.496948    6  0.8   6   2  30  30\n",
       "2      1.018 -42.873036    6  0.8   6   2  30  30\n",
       "3      1.027 -43.132955    6  0.8   6   2  30  30\n",
       "4      1.036 -43.179753    6  0.8   6   2  30  30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('Data.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 314314 entries, 0 to 314313\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   Frequency  314314 non-null  float64\n",
      " 1   S12        314314 non-null  float64\n",
      " 2   el1        314314 non-null  int64  \n",
      " 3   h1         314314 non-null  float64\n",
      " 4   l1         314314 non-null  int64  \n",
      " 5   m2         314314 non-null  int64  \n",
      " 6   px         314314 non-null  int64  \n",
      " 7   py         314314 non-null  int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 19.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>S12</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-42.088073</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.009</td>\n",
       "      <td>-42.496948</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.018</td>\n",
       "      <td>-42.873036</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.027</td>\n",
       "      <td>-43.132955</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.036</td>\n",
       "      <td>-43.179753</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2.161</td>\n",
       "      <td>-47.347711</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2.170</td>\n",
       "      <td>-47.965790</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2.179</td>\n",
       "      <td>-48.681324</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2.188</td>\n",
       "      <td>-49.490267</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.197</td>\n",
       "      <td>-50.369571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Frequency        S12  el1   h1  l1  m2  px  py\n",
       "0        1.000 -42.088073    6  0.8   6   2  30  30\n",
       "1        1.009 -42.496948    6  0.8   6   2  30  30\n",
       "2        1.018 -42.873036    6  0.8   6   2  30  30\n",
       "3        1.027 -43.132955    6  0.8   6   2  30  30\n",
       "4        1.036 -43.179753    6  0.8   6   2  30  30\n",
       "..         ...        ...  ...  ...  ..  ..  ..  ..\n",
       "129      2.161 -47.347711    6  0.8   6   2  30  30\n",
       "130      2.170 -47.965790    6  0.8   6   2  30  30\n",
       "131      2.179 -48.681324    6  0.8   6   2  30  30\n",
       "132      2.188 -49.490267    6  0.8   6   2  30  30\n",
       "133      2.197 -50.369571    6  0.8   6   2  30  30\n",
       "\n",
       "[134 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8,  4, 10], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.el1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df1[((df1['Frequency'] >= 2.4) & (df1['Frequency'] <= 3))|((df1['Frequency'] >= 5.15) & (df1['Frequency'] <= 6))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frequency</th>\n",
       "      <th>S12</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2.404</td>\n",
       "      <td>-50.726784</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2.413</td>\n",
       "      <td>-51.272862</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2.422</td>\n",
       "      <td>-51.646794</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2.431</td>\n",
       "      <td>-51.753824</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2.440</td>\n",
       "      <td>-51.548538</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>5.968</td>\n",
       "      <td>-33.933316</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>5.977</td>\n",
       "      <td>-33.763515</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>5.986</td>\n",
       "      <td>-33.615830</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>5.995</td>\n",
       "      <td>-33.487373</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>2.404</td>\n",
       "      <td>-38.538611</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Frequency        S12  el1   h1  l1  m2  px  py\n",
       "156       2.404 -50.726784    6  0.8   6   2  30  30\n",
       "157       2.413 -51.272862    6  0.8   6   2  30  30\n",
       "158       2.422 -51.646794    6  0.8   6   2  30  30\n",
       "159       2.431 -51.753824    6  0.8   6   2  30  30\n",
       "160       2.440 -51.548538    6  0.8   6   2  30  30\n",
       "...         ...        ...  ...  ...  ..  ..  ..  ..\n",
       "552       5.968 -33.933316    6  0.8   6   2  30  30\n",
       "553       5.977 -33.763515    6  0.8   6   2  30  30\n",
       "554       5.986 -33.615830    6  0.8   6   2  30  30\n",
       "555       5.995 -33.487373    6  0.8   6   2  30  30\n",
       "1157      2.404 -38.538611    8  0.8   8   4  30  30\n",
       "\n",
       "[162 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head(162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apt_dataframe(df):\n",
    "    fom=df['S12'].abs().sum()\n",
    "    return fom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fom=[]\n",
    "el1=[]\n",
    "h1=[]\n",
    "l1=[]\n",
    "m2=[]\n",
    "px=[]\n",
    "py=[]\n",
    "# filtered_df = df1[((df1['Frequency'] >= 2.4) & (df1['Frequency'] <= 3))|((df1['Frequency'] >= 5.15) & (df1['Frequency'] <= 6))]\n",
    "for i in filtered_df.index:\n",
    "    temp=apt_dataframe(df1[i:i+162])\n",
    "    fom.append(temp)\n",
    "    el1.append(filtered_df['el1'][i])\n",
    "    h1.append(filtered_df['h1'][i])\n",
    "    l1.append(filtered_df['l1'][i])\n",
    "    m2.append(filtered_df['m2'][i])\n",
    "    px.append(filtered_df['px'][i])\n",
    "    py.append(filtered_df['py'][i])\n",
    "    i=i+162"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame({'FOM':fom,'el1':el1,'h1':h1,'l1':l1,'m2':m2,'px':px,'py':py})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOM</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50544</th>\n",
       "      <td>7012.857676</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50545</th>\n",
       "      <td>7006.893172</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50546</th>\n",
       "      <td>7001.294714</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50547</th>\n",
       "      <td>6996.058558</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50548</th>\n",
       "      <td>6991.172829</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50549</th>\n",
       "      <td>6986.619291</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50550</th>\n",
       "      <td>6982.374665</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50551</th>\n",
       "      <td>6978.411586</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50552</th>\n",
       "      <td>6974.699276</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50553</th>\n",
       "      <td>6971.204008</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               FOM  el1   h1  l1  m2  px  py\n",
       "50544  7012.857676    4  1.6   4   2  28  27\n",
       "50545  7006.893172    4  1.6   4   2  28  27\n",
       "50546  7001.294714    4  1.6   4   2  28  27\n",
       "50547  6996.058558    4  1.6   4   2  28  27\n",
       "50548  6991.172829    4  1.6   4   2  28  27\n",
       "50549  6986.619291    4  1.6   4   2  28  27\n",
       "50550  6982.374665    4  1.6   4   2  28  27\n",
       "50551  6978.411586    4  1.6   4   2  28  27\n",
       "50552  6974.699276    4  1.6   4   2  28  27\n",
       "50553  6971.204008    4  1.6   4   2  28  27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOM</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "      <td>50554.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5595.144182</td>\n",
       "      <td>6.808917</td>\n",
       "      <td>1.040127</td>\n",
       "      <td>6.808917</td>\n",
       "      <td>2.025478</td>\n",
       "      <td>27.458599</td>\n",
       "      <td>27.525478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>383.792650</td>\n",
       "      <td>2.273194</td>\n",
       "      <td>0.247373</td>\n",
       "      <td>2.273194</td>\n",
       "      <td>0.224293</td>\n",
       "      <td>1.715404</td>\n",
       "      <td>1.723124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4860.961767</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5353.314409</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5493.397313</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5793.389310</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>29.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7274.265755</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FOM           el1            h1            l1            m2  \\\n",
       "count  50554.000000  50554.000000  50554.000000  50554.000000  50554.000000   \n",
       "mean    5595.144182      6.808917      1.040127      6.808917      2.025478   \n",
       "std      383.792650      2.273194      0.247373      2.273194      0.224293   \n",
       "min     4860.961767      4.000000      0.600000      4.000000      2.000000   \n",
       "25%     5353.314409      4.000000      0.800000      4.000000      2.000000   \n",
       "50%     5493.397313      6.000000      1.200000      6.000000      2.000000   \n",
       "75%     5793.389310      8.000000      1.200000      8.000000      2.000000   \n",
       "max     7274.265755     10.000000      1.600000     10.000000      4.000000   \n",
       "\n",
       "                 px            py  \n",
       "count  50554.000000  50554.000000  \n",
       "mean      27.458599     27.525478  \n",
       "std        1.715404      1.723124  \n",
       "min       25.000000     25.000000  \n",
       "25%       26.000000     26.000000  \n",
       "50%       27.000000     28.000000  \n",
       "75%       29.000000     29.000000  \n",
       "max       30.000000     30.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 1.2, 1.6, 0.6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.h1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOM</th>\n",
       "      <th>el1</th>\n",
       "      <th>h1</th>\n",
       "      <th>l1</th>\n",
       "      <th>m2</th>\n",
       "      <th>px</th>\n",
       "      <th>py</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.382875</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.342346</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.300608</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258030</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.215224</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        FOM  el1   h1  l1  m2  px  py\n",
       "0  0.382875    6  0.8   6   2  30  30\n",
       "1  0.342346    6  0.8   6   2  30  30\n",
       "2  0.300608    6  0.8   6   2  30  30\n",
       "3  0.258030    6  0.8   6   2  30  30\n",
       "4  0.215224    6  0.8   6   2  30  30"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df2[['FOM']] = scaler.fit_transform(df2[['FOM']])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Data2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.36578501098805993\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df2.drop('FOM', axis=1)\n",
    "y = df2['FOM']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "linear_reg_pred = linear_reg.predict(X_test)\n",
    "linear_reg_mse = mean_squared_error(y_test, linear_reg_pred)\n",
    "print(\"Linear Regression MSE:\", linear_reg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MSE: 0.3488647289050926\n"
     ]
    }
   ],
   "source": [
    "# SVM with RBF kernel\n",
    "svm_reg = SVR()\n",
    "svm_reg.fit(X_train, y_train)\n",
    "svm_reg_pred = svm_reg.predict(X_test)\n",
    "svm_reg_mse = mean_squared_error(y_test, svm_reg_pred)\n",
    "print(\"SVM MSE:\", svm_reg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree MSE: 0.3189059350973806\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "tree_reg = DecisionTreeRegressor(max_depth=15, random_state=42)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "tree_reg_pred = tree_reg.predict(X_test)\n",
    "tree_reg_mse = mean_squared_error(y_test, tree_reg_pred)\n",
    "print(\"Decision Tree MSE:\", tree_reg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest MSE: 0.3187651807914747\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)\n",
    "rf_reg_pred = rf_reg.predict(X_test)\n",
    "rf_reg_mse = mean_squared_error(y_test, rf_reg_pred)\n",
    "print(\"Random Forest MSE:\", rf_reg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE: 0.3657603504459743\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge_reg = Ridge(alpha=0.00001)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "ridge_reg_pred = ridge_reg.predict(X_test)\n",
    "ridge_reg_mse = mean_squared_error(y_test, ridge_reg_pred)\n",
    "print(\"Ridge Regression MSE:\", ridge_reg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor R2: 0.6809505679515497\n",
      "Linear Regression R2: 0.6340503980525158\n",
      "Random Forest Regressor R2: 0.681091385592162\n",
      "Ridge R2: 0.6340750696910165\n",
      "SVR R2: 0.650978293693661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_dt = r2_score(y_test, tree_reg_pred)\n",
    "r2_lr = r2_score(y_test, linear_reg_pred)\n",
    "r2_rf = r2_score(y_test, rf_reg_pred)\n",
    "r2_ridge = r2_score(y_test, ridge_reg_pred)\n",
    "r2_svr = r2_score(y_test, svm_reg_pred)\n",
    "\n",
    "print(\"Decision Tree Regressor R2:\", r2_dt)\n",
    "print(\"Linear Regression R2:\", r2_lr)\n",
    "print(\"Random Forest Regressor R2:\", r2_rf)\n",
    "print(\"Ridge R2:\", r2_ridge)\n",
    "print(\"SVR R2:\", r2_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1264/1264 [==============================] - 2s 1ms/step - loss: 1.0106 - val_loss: 0.9996\n",
      "Epoch 2/10\n",
      "1264/1264 [==============================] - 1s 928us/step - loss: 1.0002 - val_loss: 0.9997\n",
      "Epoch 3/10\n",
      "1264/1264 [==============================] - 1s 957us/step - loss: 1.0002 - val_loss: 0.9996\n",
      "Epoch 4/10\n",
      "1264/1264 [==============================] - 1s 938us/step - loss: 1.0002 - val_loss: 0.9996\n",
      "Epoch 5/10\n",
      "1264/1264 [==============================] - 1s 1ms/step - loss: 1.0002 - val_loss: 0.9996\n",
      "Epoch 6/10\n",
      "1264/1264 [==============================] - 1s 939us/step - loss: 1.0002 - val_loss: 0.9998\n",
      "Epoch 7/10\n",
      "1264/1264 [==============================] - 1s 968us/step - loss: 1.0002 - val_loss: 0.9998\n",
      "Epoch 8/10\n",
      "1264/1264 [==============================] - 1s 964us/step - loss: 1.0002 - val_loss: 1.0000\n",
      "Epoch 9/10\n",
      "1264/1264 [==============================] - 1s 945us/step - loss: 1.0002 - val_loss: 0.9996\n",
      "Epoch 10/10\n",
      "1264/1264 [==============================] - 1s 932us/step - loss: 1.0002 - val_loss: 0.9996\n",
      "316/316 [==============================] - 0s 661us/step - loss: 0.9996\n",
      "316/316 [==============================] - 0s 566us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(6,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN loss: 0.9995519518852234\n",
      "DNN R2: -1.9226489518242573e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "print(\"DNN loss:\",loss)\n",
    "r2_dnn=r2_score(y_test, predictions)\n",
    "print(\"DNN R2:\",r2_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lstm_data(Xtr,Xte,Ytr,Yte,T):\n",
    "#     X_train, y_train = [], []\n",
    "#     for i in range(Ytr.shape[0] - (T-1)):\n",
    "#         X_train.append(pd.DataFrame(Xtr).iloc[i:i+T].values)\n",
    "#         y_train.append(pd.DataFrame(Ytr).iloc[i + (T-1)])\n",
    "#     X_train, y_train = np.array(X_train), np.array(y_train).reshape(-1,1)\n",
    "\n",
    "#     X_test, y_test = [], []\n",
    "#     for i in range(Yte.shape[0]-(T-1)):\n",
    "#         X_test.append(pd.DataFrame(Xte).iloc[i:i+T].values)\n",
    "#         y_test.append(pd.DataFrame(Yte).iloc[i+ (T-1)])\n",
    "#     X_test, y_test = np.array(X_test), np.array(y_test).reshape(-1,1)  \n",
    "\n",
    "#     return X_train,X_test,y_train,y_test\n",
    "\n",
    "# Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "# X_train,X_test,y_train,y_test=lstm_data(Xtrain,Xtest,Ytrain,Ytest,1)\n",
    "# print(f'Train data dimensions: {X_train.shape}, {y_train.shape}')\n",
    "# print(f'Test data dimensions: {X_test.shape}, {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Reshape the input data to match the LSTM input shape\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 4))\n",
    "\n",
    "# # Reshape the test data\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1264/1264 [==============================] - 13s 7ms/step - loss: 0.5579 - val_loss: 0.4065\n",
      "Epoch 2/20\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.3551 - val_loss: 0.3421\n",
      "Epoch 3/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3416 - val_loss: 0.3304\n",
      "Epoch 4/20\n",
      "1264/1264 [==============================] - 4s 3ms/step - loss: 0.3360 - val_loss: 0.3248\n",
      "Epoch 5/20\n",
      "1264/1264 [==============================] - 5s 4ms/step - loss: 0.3293 - val_loss: 0.3230\n",
      "Epoch 6/20\n",
      "1264/1264 [==============================] - 6s 5ms/step - loss: 0.3269 - val_loss: 0.3303\n",
      "Epoch 7/20\n",
      "1264/1264 [==============================] - 5s 4ms/step - loss: 0.3249 - val_loss: 0.3273\n",
      "Epoch 8/20\n",
      "1264/1264 [==============================] - 5s 4ms/step - loss: 0.3250 - val_loss: 0.3418\n",
      "Epoch 9/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3223 - val_loss: 0.3241\n",
      "Epoch 10/20\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.3233 - val_loss: 0.3252\n",
      "Epoch 11/20\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.3202 - val_loss: 0.3391\n",
      "Epoch 12/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3207 - val_loss: 0.3230\n",
      "Epoch 13/20\n",
      "1264/1264 [==============================] - 8s 7ms/step - loss: 0.3190 - val_loss: 0.3421\n",
      "Epoch 14/20\n",
      "1264/1264 [==============================] - 10s 8ms/step - loss: 0.3192 - val_loss: 0.3239\n",
      "Epoch 15/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3195 - val_loss: 0.3186\n",
      "Epoch 16/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3159 - val_loss: 0.3282\n",
      "Epoch 17/20\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.3163 - val_loss: 0.3177\n",
      "Epoch 18/20\n",
      "1264/1264 [==============================] - 7s 6ms/step - loss: 0.3166 - val_loss: 0.3169\n",
      "Epoch 19/20\n",
      "1264/1264 [==============================] - 9s 7ms/step - loss: 0.3161 - val_loss: 0.3373\n",
      "Epoch 20/20\n",
      "1264/1264 [==============================] - 8s 6ms/step - loss: 0.3154 - val_loss: 0.3298\n",
      "316/316 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "X = df2.drop('FOM', axis=1)\n",
    "y = df2['FOM']\n",
    "X=X.values\n",
    "y=y.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Reshape the test data\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(X_train.shape[1], 1), return_sequences=True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "history=model.fit(X_train, y_train, validation_data=(X_test, y_test),epochs=20, batch_size=32)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 6, 32)             4352      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                3136      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                544       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,577\n",
      "Trainable params: 8,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40443, 6, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM R2: 0.6765359441605379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# print(\"RNN loss:\",loss)\n",
    "r2_dnn=r2_score(y_test, predictions)\n",
    "print(\"LSTM R2:\",r2_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8. ],\n",
       "        [ 0.8],\n",
       "        [ 8. ],\n",
       "        [ 2. ],\n",
       "        [25. ],\n",
       "        [30. ]],\n",
       "\n",
       "       [[10. ],\n",
       "        [ 1.2],\n",
       "        [10. ],\n",
       "        [ 2. ],\n",
       "        [28. ],\n",
       "        [26. ]],\n",
       "\n",
       "       [[ 4. ],\n",
       "        [ 1.6],\n",
       "        [ 4. ],\n",
       "        [ 2. ],\n",
       "        [26. ],\n",
       "        [25. ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8. ],\n",
       "        [ 1.2],\n",
       "        [ 8. ],\n",
       "        [ 2. ],\n",
       "        [25. ],\n",
       "        [27. ]],\n",
       "\n",
       "       [[ 8. ],\n",
       "        [ 0.8],\n",
       "        [ 8. ],\n",
       "        [ 2. ],\n",
       "        [27. ],\n",
       "        [28. ]],\n",
       "\n",
       "       [[ 4. ],\n",
       "        [ 0.8],\n",
       "        [ 4. ],\n",
       "        [ 2. ],\n",
       "        [26. ],\n",
       "        [30. ]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1012/1012 [==============================] - 7s 4ms/step - loss: 0.0129 - val_loss: 0.0082\n",
      "Epoch 2/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0090 - val_loss: 0.0081\n",
      "Epoch 3/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0087 - val_loss: 0.0081\n",
      "Epoch 4/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0085 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 6/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 7/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 8/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0085 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 10/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 11/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 12/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 13/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 14/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 16/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 19/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 20/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 21/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 24/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 25/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 27/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 29/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 30/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 31/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 34/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 35/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 36/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 37/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 40/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 45/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 46/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 47/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "1012/1012 [==============================] - 4s 4ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 49/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 50/50\n",
      "1012/1012 [==============================] - 5s 5ms/step - loss: 0.0082 - val_loss: 0.0079\n",
      "316/316 [==============================] - 1s 1ms/step\n",
      "R2 Score: 0.6821251163158764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Data2.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['FOM'])\n",
    "y = data['FOM']\n",
    "\n",
    "# Normalize/scale the data\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input to be 3D for RNN (samples, timesteps, features)\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(1, 6), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# Train the model for more epochs\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_scaled = model.predict(X_test_reshaped)\n",
    "\n",
    "# Inverse transform the predictions and true values to original scale\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_orig = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# Calculate the R2 score\n",
    "r2 = r2_score(y_test_orig, y_pred)\n",
    "print('R2 Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.23.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 99.8/99.8 MB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\vipul\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\vipul\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6736214538517045\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Data2.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data.drop(columns=['FOM'])\n",
    "y = data['FOM']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost regressor\n",
    "xgb_regressor = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.2, max_depth=1)\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate the R2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2 Score:', r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['Dual_band_comp1.csv','Dual_band_comp2.csv','Dual_band_comp3.csv','Dual_band_comp4.csv','Dual_band_comp5.csv']\n",
    "actual_foms=[]\n",
    "predicted_foms=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipul\\AppData\\Local\\Temp\\ipykernel_21704\\929445152.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fil_val['ind']=l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipul\\AppData\\Local\\Temp\\ipykernel_21704\\929445152.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fil_val['ind']=l\n",
      "C:\\Users\\vipul\\AppData\\Local\\Temp\\ipykernel_21704\\929445152.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fil_val['ind']=l\n",
      "C:\\Users\\vipul\\AppData\\Local\\Temp\\ipykernel_21704\\929445152.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fil_val['ind']=l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipul\\AppData\\Local\\Temp\\ipykernel_21704\\929445152.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fil_val['ind']=l\n"
     ]
    }
   ],
   "source": [
    "for i in names:\n",
    "    df_val=pd.read_csv(i)\n",
    "    fil_val = df_val[((df_val['Frequency'] >= 2.4) & (df_val['Frequency'] <= 3))|((df_val['Frequency'] >= 5.15) & (df_val['Frequency'] <= 6))]\n",
    "    l=list(range(1,162))\n",
    "    fil_val['ind']=l\n",
    "    fil_val=fil_val.set_index('ind')\n",
    "    fom=[]\n",
    "    el1=[]\n",
    "    h1=[]\n",
    "    l1=[]\n",
    "    m2=[]\n",
    "    px=[]\n",
    "    py=[]\n",
    "    # filtered_df = df1[((df1['Frequency'] >= 2.4) & (df1['Frequency'] <= 3))|((df1['Frequency'] >= 5.15) & (df1['Frequency'] <= 6))]\n",
    "    for i in fil_val.index:\n",
    "        temp=apt_dataframe(df_val[i:i+162])\n",
    "        fom.append(temp)\n",
    "        el1.append(df_val['el1'][i])\n",
    "        h1.append(df_val['h1'][i])\n",
    "        l1.append(df_val['l1'][i])\n",
    "        m2.append(df_val['m2'][i])\n",
    "        px.append(df_val['px'][i])\n",
    "        py.append(df_val['py'][i])\n",
    "        i=i+162\n",
    "        if(i>max(fil_val.index)):\n",
    "            break\n",
    "    val=pd.DataFrame({'FOM':fom,'el1':el1,'h1':h1,'l1':l1,'m2':m2,'px':px,'py':py})\n",
    "    X = val.drop('FOM', axis=1)\n",
    "    y = val['FOM']\n",
    "    X=X.values\n",
    "    y=y.values\n",
    "    actual_foms.append(y[0])\n",
    "    X_train = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    predictions = model.predict(X_train)\n",
    "    predicted_foms.append(predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6060.139345310001, 5786.8857522, 5695.29696869, 5599.53114536, 5909.11031321]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5549.871, 5549.871, 5459.2354, 5678.0845, 5754.0845]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_foms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAFACAYAAAChujXqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZAElEQVR4nO3df7RlZX3f8fdHBoQqCMiIBNDBONFiqkivgNUmKg0/TFaGtiwgtTpa0llp1cRVXfVH0xB/rFTbVYnESkvFMJooEhShhkimIMFoQC6C/JQyEckwAWfiDGPwB2Tg2z/2M8zxZoa5dzhz7vDc92utu+7ez37O3s/+3jP7s/c+e+5NVSFJkvrxlPkegCRJGi/DXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6syi+R7A4znooINqyZIl8z0MSZLm5IYbbvibqlo8X9vfrcN9yZIlTE9Pz/cwJEmakyT3zOf2vS0vSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktSZWYV7kv2TXJzkW0nuSPLyJAcmWZXkrvb9gNY3Sc5JsjrJzUmOHlnP8tb/riTLd9VOSZK0kM32yv0jwJeq6oXAS4A7gHcBV1bVUuDKNg9wMrC0fa0AzgVIciBwFnAscAxw1pYTgklJdt2XJEm7ix2Ge5JnAD8HnA9QVQ9X1QPAMmBl67YSOKVNLwM+WYNrgf2THAKcCKyqqg1VtRFYBZw0xn2RJEnM7sr9CGA98PtJbkzy8SRPAw6uqvtan/uBg9v0ocCakdff29q21/4TkqxIMp1kev369XPbG0mSNKtwXwQcDZxbVS8FfsDWW/AAVFUBNY4BVdV5VTVVVVOLF8/b37mXJOlJazbhfi9wb1Vd1+YvZgj777bb7bTv69rytcDhI68/rLVtr12SJI3RDsO9qu4H1iR5QWs6HrgduAzY8sT7cuDSNn0Z8Ib21PxxwKZ2+/4K4IQkB7QH6U5obZIkaYwWzbLfW4E/TLIX8G3gTQwnBhclORO4Bzit9b0ceC2wGvhh60tVbUjyfuD61u99VbVhLHshSVoQduX/TqqxfLi8e0jtxnszNTVV09PTY1ufbwpJenJ7shzHk9xQVVPjW+Pc+BvqJEnqjOEuSVJnDHdJkjpjuEuS1JnZPi0vzdmT5cEXSeqN4S5JetIoduVf6urnqsHb8pIkdcZwlySpM96Wlzricw6SwHCXpJ3n2ZR2U96WlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOrOgnpb3NxtNlvWWpPnhlbskSZ0x3CVJ6ozhLklSZxbUZ+5S73zOQRJ45S5JUncMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6syswj3Jd5LckuSmJNOt7cAkq5Lc1b4f0NqT5Jwkq5PcnOTokfUsb/3vSrJ81+ySJEkL21yu3F9dVUdV1VSbfxdwZVUtBa5s8wAnA0vb1wrgXBhOBoCzgGOBY4CztpwQSJKk8Xkit+WXASvb9ErglJH2T9bgWmD/JIcAJwKrqmpDVW0EVgEnPYHtS5KkbZhtuBfwp0luSLKitR1cVfe16fuBg9v0ocCakdfe29q21y5JksZo0Sz7vbKq1iZ5FrAqybdGF1ZVJalxDKidPKwAeM5znjOOVUqStKDM6sq9qta27+uASxg+M/9uu91O+76udV8LHD7y8sNa2/baZ27rvKqaqqqpxYsXz21vJEnSjsM9ydOS7LtlGjgBuBW4DNjyxPty4NI2fRnwhvbU/HHApnb7/grghCQHtAfpTmhtkiRpjGZzW/5g4JIkW/p/uqq+lOR64KIkZwL3AKe1/pcDrwVWAz8E3gRQVRuSvB+4vvV7X1VtGNueSJIkAFI1lo/Kd4mpqamanp4e3wqHE5RdYzeu47yx3pNnzSfLek/ek6TmSW4Y+a/jE+dvqJMkqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktQZw12SpM4Y7pIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZ2Yd7kn2SHJjki+2+SOSXJdkdZLPJtmrtT+1za9uy5eMrOPdrf3OJCeOfW8kSdKcrtx/A7hjZP5DwNlV9XxgI3Bmaz8T2Njaz279SHIkcAbwIuAk4GNJ9nhiw5ckSTPNKtyTHAb8IvDxNh/gNcDFrctK4JQ2vazN05Yf3/ovAy6sqoeq6m5gNXDMGPZBkiSNmO2V++8C/xF4tM0/E3igqja3+XuBQ9v0ocAagLZ8U+v/WPs2XiNJksZkh+Ge5JeAdVV1wwTGQ5IVSaaTTK9fv34Sm5QkqSuzuXJ/BfDLSb4DXMhwO/4jwP5JFrU+hwFr2/Ra4HCAtvwZwPdG27fxmsdU1XlVNVVVU4sXL57zDkmStNDtMNyr6t1VdVhVLWF4IO6qqnod8GXg1NZtOXBpm76szdOWX1VV1drPaE/THwEsBb4+tj2RJEkALNpxl+16J3Bhkg8ANwLnt/bzgU8lWQ1sYDghoKpuS3IRcDuwGXhzVT3yBLYvSZK2IcNF9e5pamqqpqenx7fCZHzrmmk3ruO8sd6TZ80ny3pP3pOk5kluqKqpsa1wjvwNdZIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktQZw12SpM4Y7pIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqzA7DPcneSb6e5JtJbkvy3tZ+RJLrkqxO8tkke7X2p7b51W35kpF1vbu135nkxF22V5IkLWCzuXJ/CHhNVb0EOAo4KclxwIeAs6vq+cBG4MzW/0xgY2s/u/UjyZHAGcCLgJOAjyXZY4z7IkmSmEW41+DBNrtn+yrgNcDFrX0lcEqbXtbmacuPT5LWfmFVPVRVdwOrgWPGsROSJGmrWX3mnmSPJDcB64BVwF8CD1TV5tblXuDQNn0osAagLd8EPHO0fRuvkSRJYzKrcK+qR6rqKOAwhqvtF+6qASVZkWQ6yfT69et31WYkSerWnJ6Wr6oHgC8DLwf2T7KoLToMWNum1wKHA7TlzwC+N9q+jdeMbuO8qpqqqqnFixfPZXiSJInZPS2/OMn+bXof4BeAOxhC/tTWbTlwaZu+rM3Tll9VVdXaz2hP0x8BLAW+Pqb9kCRJzaIdd+EQYGV7sv0pwEVV9cUktwMXJvkAcCNwfut/PvCpJKuBDQxPyFNVtyW5CLgd2Ay8uaoeGe/uSJKkDBfVu6epqamanp4e3wqT8a1rpt24jvPGek+eNZ8s6z15T5KaJ7mhqqbGtsI58jfUSZLUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktQZw12SpM4Y7pIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ3ZYbgnOTzJl5PcnuS2JL/R2g9MsirJXe37Aa09Sc5JsjrJzUmOHlnX8tb/riTLd91uSZK0cM3myn0z8PaqOhI4DnhzkiOBdwFXVtVS4Mo2D3AysLR9rQDOheFkADgLOBY4BjhrywmBJEkanx2Ge1XdV1XfaNN/C9wBHAosA1a2biuBU9r0MuCTNbgW2D/JIcCJwKqq2lBVG4FVwEnj3BlJkjTHz9yTLAFeClwHHFxV97VF9wMHt+lDgTUjL7u3tW2vfeY2ViSZTjK9fv36uQxPkiQxh3BP8nTgc8Dbqur7o8uqqoAax4Cq6ryqmqqqqcWLF49jlZIkLSizCvckezIE+x9W1edb83fb7Xba93WtfS1w+MjLD2tt22uXJEljNJun5QOcD9xRVR8eWXQZsOWJ9+XApSPtb2hPzR8HbGq3768ATkhyQHuQ7oTWJkmSxmjRLPq8Ang9cEuSm1rbe4APAhclORO4BzitLbsceC2wGvgh8CaAqtqQ5P3A9a3f+6pqwzh2QpIkbbXDcK+qPweyncXHb6N/AW/ezro+AXxiLgOUJElz42+okySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktQZw12SpM4Y7pIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJndhjuST6RZF2SW0faDkyyKsld7fsBrT1JzkmyOsnNSY4eec3y1v+uJMt3ze5IkqTZXLlfAJw0o+1dwJVVtRS4ss0DnAwsbV8rgHNhOBkAzgKOBY4BztpyQiBJksZrh+FeVdcAG2Y0LwNWtumVwCkj7Z+swbXA/kkOAU4EVlXVhqraCKzi758wSJKkMdjZz9wPrqr72vT9wMFt+lBgzUi/e1vb9tolSdKYPeEH6qqqgBrDWABIsiLJdJLp9evXj2u1kiQtGDsb7t9tt9tp39e19rXA4SP9Dmtt22v/e6rqvKqaqqqpxYsX7+TwJElauHY23C8Dtjzxvhy4dKT9De2p+eOATe32/RXACUkOaA/SndDaJEnSmC3aUYcknwFeBRyU5F6Gp94/CFyU5EzgHuC01v1y4LXAauCHwJsAqmpDkvcD17d+76uqmQ/pSZKkMcjwkfnuaWpqqqanp8e3wmR865ppN67jvLHek2fNJ8t6T96TpOZJbqiqqbGtcI78DXWSJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6ozhLklSZwx3SZI6Y7hLktQZw12SpM4Y7pIkdcZwlySpM4a7JEmdMdwlSeqM4S5JUmcMd0mSOmO4S5LUGcNdkqTOGO6SJHXGcJckqTOGuyRJnTHcJUnqjOEuSVJnDHdJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkzhrskSZ0x3CVJ6szEwz3JSUnuTLI6ybsmvX1Jkno30XBPsgfwP4CTgSOBX0ly5CTHIElS7yZ95X4MsLqqvl1VDwMXAssmPAZJkro26XA/FFgzMn9va5MkSWOyaL4HMFOSFcCKNvtgkjvncTgHAX8zq57Jrh3JwmC9J2v29QZrPh6+xydrPt/jzx3nyuZq0uG+Fjh8ZP6w1vaYqjoPOG+Sg9qeJNNVNTXf41gorPdkWe/Js+aTtZDrPenb8tcDS5MckWQv4AzgsgmPQZKkrk30yr2qNid5C3AFsAfwiaq6bZJjkCSpdxP/zL2qLgcun/R2d9Ju8fHAAmK9J8t6T541n6wFW+9U1XyPQZIkjZG/flaSpM4Y7pIkdeYJh3uSR5LclOS2JN9M8vYkO73eJFcn2e5/XUjy4M6uewfbvSDJqbti3XOV5IVJ/iLJQ0neMWOZ9R6zJK9LcnOSW5J8LclLRpZZ7zFLsqzV+6Yk00leOWO5Nd9FkrwsyebRcVnv8UvyqiSbWl1vSvJbkx7DOB6o+1FVHQWQ5FnAp4H9gLPGsO6FagPw68Ap21hmvcfvbuDnq2pjkpMZHsI5ti2z3uN3JXBZVVWSFwMXAS8cWW7Nd4H2tz0+BPzpjEXWe9f4SlX90nxtfKy35atqHcNvl3tLBm9M8tEty5N8Mcmr2vS57az9tiTvnct2kpzdXndlksWt7d8mub6deX4uyT9o7RckOaddkX17y5ldG99HM/yFuv8LPGsH23xZW8c3k3w9yb5J9k7y++2K78Ykr25935jkC0lWJflOkrck+Q+tz7VJDmz9rk7ykXZmd2uSY7bUsaquB/5uB6V4LnAA8J/amH4tyafb9E1Jvp/hqvSDSa4ZqffVmXFHYIHX+2tVtbFt+lqGX65kvXddvR+srU/yPg3Y5lO9SU4CvsTwK6rf0/bpvyRZ39Z5Y5I/SXJVkl/M1mPKxiQXzbbeC6HmzVuBzwHrHmdYRwPPZniPX9m2+/lsvQLdlOTkJBcm+eOR9/hNmcNV8wKp92zqsK0xvShbjyk3J1ma4Zjy5pHX/XZ2dEypqif0BTy4jbYHgIOBNwIfHWn/IvCqNn1g+74HcDXw4jZ/NTD1ONsr4HVt+re2rB945kifDwBvbdMXAH/EcCJzJMMfrgH4F8Cqtv2famM+dTvb3Av4NvCyNr8fw12PtzP8X30Yrjz+Cti77fdqYF9gMbAJ+LXW72zgbSP7+r/b9M8Bt87Y7m8D79hWvUfH1Mb+08C/AW4eqc8fAycALwW+OlLvHwC/YL1/st6t/R3Ax633rq038M+BbzHcpXr5zPd4W+8a4IjWtonhmHIjcHFre3qr+W8CK4ED276sAa7BY8pjNWc4QfqzNuYLRsfF1vf4YzVvY39B2+7dwCtanz8Bjm8/v8+0tr2BH4/si/WGVwHfA77ZavaiOYzp90bqsxewD8Mx5c9GXns7cPj2alxV8/pA3WlJvsHwj/VFDD+02XgU+Gyb/gNgy+d1P5vkK0luAV7X1rnFF6rq0aq6neEAAcMP4jNV9UhV/TVw1eNs8wXAfTVcTVNV36+qzW3bf9DavgXcA/xMe82Xq+pvq2o9wxvj/7T2W4AlI+v+THv9NcB+SfafXRl+ckwMB8RHgfsYrnLeyfCmeLiqbgSe12pzB8Mb5pmz3M6CqXc7az8TeOeOxoT1fkL1rqpLquqFDB89vX8bYzoOuKaq7m7zW67uVwOvTPLrwP6t/evAq4F/xVDvpwP/EI8pozX/XeCdVfXo44xpZs0faN/vAz7car4n8AhDYJ2Y5EaGkzQYTnhnYyHU+xvAc6vqJQxh/YU5jOkv2HpMeW5V/agdU56V5KcyPBO0sarWbGOdjxl7uCd5HsMPfx2wecY29m59jmC4Qjq+ql7McPa9905ucss/+guAt1TVPwLeO2N9D40OcSe3M1ej23x0ZP5RfvJZh5m3JLd5i3J7tlHvvwR+GfgRwz/Wl7Z6P5XhTXwxwxvPeo/MZ/js9+PAsqr63vY2Yr23uc2dfn+3A+Lzkhy0vQ3NqPmlDFdL+wBfZbhafxiYBt7DUOvleExhxvwUcGGS7wCnAh9Lcsq2NrKN9/hNwK8y1PwVwHOAQ9o2/yvwNYafhfVu8y2oH2wzlwN7Pt57fMaLP83WY8rlSV7TFv0Rw8/udLaeHG3XWMO9fXbyPxlusxTwHeCoJE9JcjjD33OH4fbDD4BNSQ4GTp7DZp7CsIMwnKn/eZveF7gvyZ4MZ307cg1wepI9khzCcOa/PXcChyR5GUD7XGQR8JUt20ryMwxv+rn+FbvT2+tfCWyqqk2zfN2dDLfaPg18lOFqZQ3Dg2B3A5cw3K76aYZ6rwOWte09bw7j677eSZ4DfB54fVX9v8cZk/UeT72fnwx/fivJ0QwnQjNPqK4Ffi7JP2Y4pny8HVMebuP4b8CtwFGt/1UMn98fxxDwHlNGal5VR1TVkqpawnDC+e+r6gszXnctw+3klQzv8QMYjuHHArcxvPcXtTHtx/DX1k4Dfh742TmMr/t6J3n2yHv8GIZ9nvke3+aY2snVt6vqHIaT2Re3/p9l+HsspzIE/eMax9Py+yS5ieF2zWbgU8CH27KvMhz4bme4XfYNgKr65sjtnDWt32z9ADgmyW8yHEBPb+3/GbgOWN++77uD9VwCvKaN7a8YboVsU1U9nOR04PeS7MNwRvXPgI8B57bbSJuBN1bVQ5nbnw38cavFngyf4ZLk2QxXIvsBjyZ5G3BkVX0feFqSWxnOXh9mOIM+BTixjekpbXw/YqjVFa3e1wK/0tqunsP4uq83w+d+z2S4mgHYXFv/kpT1Hn+9/yXwhiR/17Z1egtu2rFkH4bPUh9lOPBvZOvV2j9luN3+Q4ZabPmY5H8B/71Nr8RjysyaP56njRzDH2I4Gd0P+CcMz5A8vY3vxwzPSFzX3uNfAf418F2s98x6nwr8uySb27bOGHmPXw78alX99XbGdBrw+vbv437gd9o+3JZkX2BtVd23o0H562fnUZKrGR6Ym57vsSwE1nuyrPfkWfPJ2p3r7W+okySpM7vtlXuS6xg+ixv1+qq6ZRdv9xKG/woy6p1VdcWu3O58s96TZb0nz5pPlvWeX7ttuEuSpJ3jbXlJkjpjuEuS1BnDXZKkzhjukiR1xnCXJKkz/x/OBpNLAZVh2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the actual and predicted FOMs as a bar graph\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(names, actual_foms, color = 'b', width = 0.25)\n",
    "ax.bar(names, predicted_foms, color = 'r', width = 0.25)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
